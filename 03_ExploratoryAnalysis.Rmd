---
title: "03_ExploratoryAnalysis"
author: "Hiroki YAMAMOTO"
date: "2022/2/6"
output: html_document
---


```{r}
library(tidyverse)
library(lubridate)
library(here)
library(lme4)
library(car)
library(performance)
library(effectsize)
```

# 除外する参加者のIDを指定
```{r}
par_remove <- str_c("participant_test_", c("04", "16", "26", "28", "39"))

w_size <- seq(1, 3, by = 0.5)
w_size <- 3
```

```{r}
read_csv("d_script.csv", col_types = "ccdd") %>% 
  mutate(time_tmp1 = as.numeric(hms(time)),
         time_tmp2 = if_else(order == 2, time_tmp1 + 10 * 60, time_tmp1),
         comment_timestamp = time_tmp2 * 1000 * 1000) %>% 
  select(!contains("_tmp")) %>% 
  mutate(participant_name = str_c("participant_test_", str_sub(participant, start = -2, end = -1)),
         participant_name = if_else(participant == "participant19", "participant_test_18 (2)", participant_name)) %>%  filter(!participant_name %in% par_remove) %>% 
mutate(id = row_number()) -> d_comment

read_csv("united.csv", col_types = "cDcccdddddcddddddddlllld") %>% 
  select(participant_name, image_name, frame_id, ends_with("timestamp"), gaze, face_detect, Overlap, MM) -> d_gaze

d_gaze %>% 
  select(participant_name, MM) %>% 
  distinct()-> d_participant
```

```{r}
d_comment %>% 
  filter(!is.na(category)) %>% 
  pull(participant_name) %>% 
  unique()
```

```{r}
for (j in 1:length(w_size)){
  w_size_tmp <- w_size[j]
  
  tibble(N_window = numeric(),
         Prop_NA = numeric(),
         Prop_Overlap = numeric()) -> d_mmtime

  for (i in 1:nrow(d_comment)){
    d_comment %>% 
      filter(id == i) -> d_target # ある特定の発話を抽出
    d_gaze %>% 
      filter(participant_name == d_target$participant_name) %>% 
      mutate(diff_time = movie_timestamp - d_target$comment_timestamp) %>% 
      filter(diff_time > - w_size_tmp * 1000 * 1000 & diff_time < w_size_tmp * 1000 * 1000) %>% # 発話時刻との時差が閾値以下の画像を抽出
      summarise(N_window = n(), # 時間窓内にある画像枚数
                Prop_NA = sum(is.na(Overlap))/N_window, # 顔または視線が検出されていない割合
                Prop_Overlap = if_else(Prop_NA == 1, NA_real_, sum(Overlap, na.rm = TRUE)/N_window)) -> d_tmp
    bind_rows(d_mmtime, d_tmp) -> d_mmtime
  }
  
  filename <- str_c("wsize_", w_size_tmp, "s.csv")

  bind_cols(d_comment, d_mmtime) %>% 
    mutate(w_size_set = w_size_tmp,
           category = if_else(category == 1, "Appropriate", "Others")) %>% 
    write_csv(here("Result", filename))
}
```

```{r}
list.files(getwd(), pattern = "s.csv", recursive = TRUE) %>% 
  map_df(~read_csv(.x, col_types = "ccdcdcddddd")) -> df_mm

df_mm %>% 
  group_by(w_size_set, participant_name, category) %>%
  summarise(Comment_count = n(),
            NA_count = sum(is.na(Prop_Overlap)),
            Cooccurrence_count = if_else(Comment_count == NA_count, NA_integer_, sum(Prop_Overlap > 0, na.rm = TRUE)),
            Prop_Cooccurrence = Cooccurrence_count / Comment_count,
            .groups = "drop") -> df_cooccurence
# 全ての発話において，顔または視線が検出されていないとき，Prop_CooccurenceはNAとなる
df_cooccurence %>% 
  group_by(w_size_set, category) %>% 
  summarise(N_participant = length(unique(participant_name)),
            N_allNA = sum(is.na(Prop_Cooccurrence)),
            .groups = "drop")
  
df_cooccurence %>%  
  filter(!is.na(Prop_Cooccurrence)) %>% 
  filter(!is.na(category)) %>% 
  left_join(d_participant, by = "participant_name") %>% 
  ggplot(aes(x = category, y = Prop_Cooccurrence, color = MM)) +
  geom_point() +
  geom_line(aes(group = participant_name)) +
  facet_wrap(~w_size_set)
  labs(x = "発話の種類", y = "発話付近に顔を注視した割合") +
  theme(axis.title = element_text(size = 15, face = "bold"),
        axis.text = element_text(size = 12, color = "black"))
```

```{r}
df_cooccurence %>%  
  filter(!is.na(Prop_Cooccurrence)) %>% 
  filter(!is.na(category)) %>% 
  left_join(d_participant, by = "participant_name") -> df

fit <- glmer(cbind(Cooccurrence_count, Comment_count - Cooccurrence_count) ~ category * MM + (1 |participant_name),
             data = df, family = "binomial")
check_overdispersion(fit)


fit <- lmer(Prop_Cooccurrence ~ category * MM + (1  | participant_name), data = df)

Anova(fit)

summary(fit)

library(modelbased)
estimate_contrasts(fit, contrast = c("category"), at = "MM", length = 3, adjust = "holm")
```

